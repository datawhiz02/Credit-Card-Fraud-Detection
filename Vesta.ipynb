{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50f11b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the basic numpy and pandas libraries\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f934cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the datasets \n",
    "train_transaction = pd.read_csv('train_transaction.csv')\n",
    "test_transaction = pd.read_csv('test_transaction.csv')\n",
    "train_identity = pd.read_csv('train_identity.csv')\n",
    "test_identity = pd.read_csv('test_identity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1101e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge datasets to create a single train test dataset\n",
    "train_merged = pd.merge(train_transaction, train_identity, on = 'TransactionID', how = 'left')\n",
    "test_merged = pd.merge(test_transaction, test_identity, on = 'TransactionID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "127322c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (590540, 434)\n",
      "test: (506691, 433)\n"
     ]
    }
   ],
   "source": [
    "#Checking shape of the datasets\n",
    "print('train:',train_merged.shape)\n",
    "print('test:', test_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6d17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are primarily interested in features that have less than 10% missing data\n",
    "valid_features = train_merged.isnull().sum()/len(train_merged)*100 < 10\n",
    "valid_features = pd.DataFrame(valid_features[valid_features == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "335e4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting only valid features in our dataset\n",
    "train = train_merged[list(valid_features.index)]\n",
    "test = test_merged[[col for col in list(valid_features.index) if col != 'isFraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f70ca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (590540, 112)\n",
      "test: (506691, 111)\n"
     ]
    }
   ],
   "source": [
    "#Checking the shape of datsets after filtering for valid columns\n",
    "print('train:',train.shape)\n",
    "print('test:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17bc2b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V312</th>\n",
       "      <th>V313</th>\n",
       "      <th>V314</th>\n",
       "      <th>V315</th>\n",
       "      <th>V316</th>\n",
       "      <th>V317</th>\n",
       "      <th>V318</th>\n",
       "      <th>V319</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ...   V312  V313  V314  V315  V316  \\\n",
       "0    NaN  150.0    discover  142.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "1  404.0  150.0  mastercard  102.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "2  490.0  150.0        visa  166.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "3  567.0  150.0  mastercard  117.0  ...  135.0   0.0   0.0   0.0  50.0   \n",
       "4  514.0  150.0  mastercard  102.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "     V317   V318  V319  V320  V321  \n",
       "0   117.0    0.0   0.0   0.0   0.0  \n",
       "1     0.0    0.0   0.0   0.0   0.0  \n",
       "2     0.0    0.0   0.0   0.0   0.0  \n",
       "3  1404.0  790.0   0.0   0.0   0.0  \n",
       "4     0.0    0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the dataframes\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef9c7a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>V312</th>\n",
       "      <th>V313</th>\n",
       "      <th>V314</th>\n",
       "      <th>V315</th>\n",
       "      <th>V316</th>\n",
       "      <th>V317</th>\n",
       "      <th>V318</th>\n",
       "      <th>V319</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>18403224</td>\n",
       "      <td>31.95</td>\n",
       "      <td>W</td>\n",
       "      <td>10409</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>18403263</td>\n",
       "      <td>49.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4272</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>18403310</td>\n",
       "      <td>171.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4476</td>\n",
       "      <td>574.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>18403310</td>\n",
       "      <td>284.95</td>\n",
       "      <td>W</td>\n",
       "      <td>10989</td>\n",
       "      <td>360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>282.540009</td>\n",
       "      <td>282.540009</td>\n",
       "      <td>282.540009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>18403317</td>\n",
       "      <td>67.95</td>\n",
       "      <td>W</td>\n",
       "      <td>18018</td>\n",
       "      <td>452.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>67.949997</td>\n",
       "      <td>67.949997</td>\n",
       "      <td>183.850006</td>\n",
       "      <td>67.949997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
       "0        3663549       18403224           31.95         W  10409  111.0   \n",
       "1        3663550       18403263           49.00         W   4272  111.0   \n",
       "2        3663551       18403310          171.00         W   4476  574.0   \n",
       "3        3663552       18403310          284.95         W  10989  360.0   \n",
       "4        3663553       18403317           67.95         W  18018  452.0   \n",
       "\n",
       "   card3       card4  card5  card6  ...       V312        V313        V314  \\\n",
       "0  150.0        visa  226.0  debit  ...   0.000000    0.000000    0.000000   \n",
       "1  150.0        visa  226.0  debit  ...  77.000000    0.000000    0.000000   \n",
       "2  150.0        visa  226.0  debit  ...   0.000000    0.000000    0.000000   \n",
       "3  150.0        visa  166.0  debit  ...   0.000000  282.540009  282.540009   \n",
       "4  150.0  mastercard  117.0  debit  ...  67.949997   67.949997  183.850006   \n",
       "\n",
       "         V315  V316  V317  V318  V319   V320  V321  \n",
       "0    0.000000   0.0   0.0   0.0   0.0    0.0   0.0  \n",
       "1    0.000000   0.0   0.0   0.0   0.0    0.0   0.0  \n",
       "2    0.000000   0.0   0.0   0.0   0.0  263.0   0.0  \n",
       "3  282.540009   0.0   0.0   0.0   0.0    0.0   0.0  \n",
       "4   67.949997   0.0   0.0   0.0   0.0    0.0   0.0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583e6667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    569877\n",
       "1     20663\n",
       "Name: TransactionID, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the number of fraud transactions in the training dataset\n",
    "train.groupby(['isFraud'])['TransactionID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed144a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the training and testing dataset as both sets need to perform data cleaning. Also categorize the categorical columns according to the correct data type\n",
    "combined = pd.concat([train.drop('isFraud',axis=1),test])\n",
    "combined = combined.astype({'ProductCD': 'category','card1': 'category','card2': 'category','card3': 'category','card4': 'category','card5': 'category','card6': 'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b896ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 111)\n"
     ]
    }
   ],
   "source": [
    "#Checking the shape of the combined dataset\n",
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3980bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating the numerical and categorical data to perform the imputation later\n",
    "combined_num = combined.select_dtypes(include=np.number)\n",
    "combined_cat = combined.select_dtypes(exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7354ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing imputation for numerical columns\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer_median = SimpleImputer(strategy=\"median\")\n",
    "combined_filled_median = combined_num.copy()\n",
    "imputer_median.fit(combined_filled_median)\n",
    "combined_filled_median = pd.DataFrame(imputer_median.transform(combined_filled_median),columns=combined_filled_median.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "953aa3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing imputation for categorical columns\n",
    "imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
    "combined_filled_cat = combined_cat.copy()\n",
    "imputer_cat.fit(combined_filled_cat)\n",
    "combined_filled_cat = pd.DataFrame(imputer_cat.transform(combined_filled_cat),columns=combined_filled_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff9afc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the filled datasets\n",
    "combined_num_cat = pd.concat([combined_filled_median,combined_filled_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6b11068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductCD: 5\n",
      "card1: 17091\n",
      "card2: 501\n",
      "card3: 133\n",
      "card4: 4\n",
      "card5: 138\n",
      "card6: 4\n"
     ]
    }
   ],
   "source": [
    "#Checking the number of unique values in the categorical columns before doing one-hot encoding\n",
    "def unique_values_counter(cols):\n",
    "    for col in cols:\n",
    "        print(\"{}: {}\".format(col, combined_cat[col].nunique()))\n",
    "    \n",
    "unique_values_counter(combined_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8ddb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the columns with too many unique values\n",
    "combined_dropped = combined_num_cat.drop(['TransactionID','card1', 'card2', 'card3', 'card5'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aef457f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the numerical columns to perform standard scaling\n",
    "numerical_column_names = combined_dropped.select_dtypes(include=['number']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abb9bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(combined_dropped.loc[:, numerical_column_names])\n",
    "combined_scaled = combined_dropped.copy()\n",
    "combined_scaled.loc[:, numerical_column_names] = scaler.transform(combined_scaled.loc[:, numerical_column_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8513a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the categorical columns to do one-hot-encoding\n",
    "categorical_column_names = combined_scaled.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6822d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform One-Hot-Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "encoder.fit(combined_scaled.loc[:, categorical_column_names])\n",
    "combined_encoded_columns = encoder.transform(combined_scaled.loc[:, categorical_column_names])\n",
    "combined_encoded_df = pd.DataFrame.sparse.from_spmatrix(combined_encoded_columns, columns=encoder.get_feature_names_out(), index=combined_scaled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d963f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 13)\n"
     ]
    }
   ],
   "source": [
    "print(combined_encoded_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "647033f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 116)\n"
     ]
    }
   ],
   "source": [
    "combined_dropcat = combined_scaled.drop(categorical_column_names, axis=1)\n",
    "combined_final = pd.concat([combined_dropcat,combined_encoded_df], axis=1)\n",
    "print(combined_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5acab9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavan\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pavan\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 10)\n"
     ]
    }
   ],
   "source": [
    "#There are more than 100 different columns in the combined_final dataset. This is just too many features to be modeled simply. We perform PCA to reduce the features to 10 features.\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(combined_final)\n",
    "combined_pca = pca.transform(combined_final)\n",
    "print(combined_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e3acc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the train and test datasets\n",
    "len_train = len(train) #This is the number of rows in which we have label 'isFraud'\n",
    "X_train = pd.DataFrame(combined_pca).iloc[:len_train]\n",
    "y_train = train['isFraud']\n",
    "X_test = pd.DataFrame(combined_pca).iloc[len_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0844da7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 10)\n",
      "(506691, 10)\n"
     ]
    }
   ],
   "source": [
    "#Checking the shape of the train and test set after PCA\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20c99359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1139754, 10) (1139754,)\n",
      "0    569877\n",
      "1    569877\n",
      "Name: isFraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Our dataset is also inbalanced. Only ~3% of the label are fraudulent. We use oversampling and undersampling to create a balanced training dataset.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(X_train_smote.shape, y_train_smote.shape)\n",
    "print(pd.value_counts(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863e586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
